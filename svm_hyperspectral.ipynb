{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sio.loadmat(\"D:\\Masters\\sem2\\gnr602/nn_bagging\\Indian_pines_corrected.mat\")\n",
    "labels = sio.loadmat(\"D:\\Masters\\sem2\\gnr602/nn_bagging\\Indian_pines_gt.mat\")\n",
    "data = data[sorted(data.keys())[-1]]\n",
    "labels = labels[sorted(labels.keys())[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reshaped = np.reshape(data, (-1, data.shape[2]))\n",
    "\n",
    "# Preprocess the data using PCA\n",
    "pca = PCA(n_components=30)\n",
    "data_pca = pca.fit_transform(data_reshaped)\n",
    "\n",
    "# Reshape labels\n",
    "labels_reshaped = np.reshape(labels, (-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_labels_idx = np.where(labels_reshaped != 0)[0]\n",
    "data_pca = data_pca[nonzero_labels_idx]\n",
    "labels_reshaped = labels_reshaped[nonzero_labels_idx]\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_idx = np.random.choice(data_pca.shape[0], int(0.7 * data_pca.shape[0]), replace=False)\n",
    "test_idx = np.setdiff1d(np.arange(data_pca.shape[0]), train_idx)\n",
    "\n",
    "X_train, y_train = data_pca[train_idx], labels_reshaped[train_idx]\n",
    "X_test, y_test = data_pca[test_idx], labels_reshaped[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneVsRestClassifier(estimator=SVC(C=1, gamma=0.1))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneVsRestClassifier</label><div class=\"sk-toggleable__content\"><pre>OneVsRestClassifier(estimator=SVC(C=1, gamma=0.1))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, gamma=0.1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, gamma=0.1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneVsRestClassifier(estimator=SVC(C=1, gamma=0.1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train SVM with RBF kernel using one-vs-all method\n",
    "clf_ova_rbf = OneVsRestClassifier(SVC(kernel='rbf', C=1, gamma=0.1))\n",
    "clf_ova_rbf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test SVM with RBF kernel using one-vs-all method\n",
    "y_pred_ova_rbf = clf_ova_rbf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (one-vs-one, RBF kernel): 0.24\n"
     ]
    }
   ],
   "source": [
    "accuracy_ova_rbf = accuracy_score(y_test, y_pred_ova_rbf)\n",
    "print(\"Accuracy (one-vs-one, RBF kernel):\", accuracy_ova_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "\n",
    "# Load iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply Linear Discriminant Analysis to reduce dimensionality\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "X_train_lda = lda.fit_transform(X_train, y_train)\n",
    "X_test_lda = lda.transform(X_test)\n",
    "\n",
    "# Train a binary SVM classifier for each class of the reduced data\n",
    "svm_models = []\n",
    "for i in np.unique(y_train):\n",
    "    y_train_binary = np.zeros(y_train.shape)\n",
    "    y_train_binary[y_train == i] = 1\n",
    "    svm = SVC(kernel='linear')\n",
    "    svm.fit(X_train_lda, y_train_binary)\n",
    "    svm_models.append(svm)\n",
    "\n",
    "# Assign a score to each test point for each class using the trained SVM classifiers\n",
    "scores = np.zeros((X_test_lda.shape[0], len(np.unique(y_train))))\n",
    "for i, svm in enumerate(svm_models):\n",
    "    scores[:, i] = svm.decision_function(X_test_lda)\n",
    "\n",
    "# Calculate the similarity between the test point and each class using the score of the SVM classifier and the distance to the nearest neighbor of that class in the reduced data\n",
    "similarity_scores = np.zeros((X_test_lda.shape[0], len(np.unique(y_train))))\n",
    "for i in range(X_test_lda.shape[0]):\n",
    "    for j, svm in enumerate(svm_models):\n",
    "        dist = distance.euclidean(X_test_lda[i], X_train_lda[y_train == j][np.argmin(distance.cdist([X_test_lda[i]], X_train_lda[y_train == j]))])\n",
    "        similarity_scores[i, j] = scores[i, j] / dist\n",
    "\n",
    "# Assign the test point to the class with the highest similarity score\n",
    "predicted = np.argmax(similarity_scores, axis=1)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, predicted)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10249, 30)\n",
      "(10249, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "import os,time\n",
    "from sklearn.multiclass import  OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = sio.loadmat(\"D:\\Masters\\sem2\\gnr602/nn_bagging\\Indian_pines_corrected.mat\")\n",
    "labels = sio.loadmat(\"D:\\Masters\\sem2\\gnr602/nn_bagging\\Indian_pines_gt.mat\")\n",
    "data = data[sorted(data.keys())[-1]]\n",
    "labels = labels[sorted(labels.keys())[-1]]\n",
    "\n",
    "def applyPCA(X, n_components=30, seed=1):\n",
    "    newX = np.reshape(X, (-1, X.shape[2]))\n",
    "    pca = PCA(n_components=n_components, whiten=True, random_state=seed)\n",
    "    newX = pca.fit_transform(newX)\n",
    "    newX = np.reshape(newX, (X.shape[0], X.shape[1], n_components))\n",
    "    return newX\n",
    "\n",
    "# data.shape\n",
    "\n",
    "data = applyPCA(data)\n",
    "# data.shape\n",
    "\n",
    "# labels = gt_data[sorted(gt_data.keys())[-1]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = data.reshape(data.shape[0]*data.shape[1],data.shape[2])\n",
    "data.shape\n",
    "\n",
    "labels = labels.reshape(-1,1)\n",
    "nonzero_labels_idx = np.where(labels != 0)[0]\n",
    "data = data[nonzero_labels_idx]\n",
    "labels = labels[nonzero_labels_idx]\n",
    "print(data.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "combine = np.concatenate((data,labels),axis=1)\n",
    "combine\n",
    "\n",
    "df = pd.DataFrame(combine)\n",
    "\n",
    "# df\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "C_values = [0.1, 1, 10, 100]\n",
    "kernel_type = ['linear','poly','rbf']\n",
    "accuracy = []\n",
    "\n",
    "for kernel in kernel_type:\n",
    "  for C in C_values:\n",
    "      # Initialize SVM classifier with current C value\n",
    "      svm = SVC(kernel=kernel, C=C)\n",
    "\n",
    "      start_time1 = time.time()\n",
    "      svm_ovr = OneVsRestClassifier(svm).fit(X_train, y_train)\n",
    "      Time_taken_ovr = time.time() - start_time1\n",
    "      y_test_ovr = svm_ovr.predict(X_test)\n",
    "\n",
    "      acc_ovr = accuracy_score(y_test, y_test_ovr)\n",
    "      accuracy.append(acc_ovr)\n",
    "\n",
    "      \n",
    "      # # Train SVM classifier\n",
    "      # svm.fit(X_train, y_train)\n",
    "      \n",
    "      # # Get number of support vectors\n",
    "      # n_support_vectors = svm.n_support_\n",
    "      \n",
    "      # # Print number of support vectors for current C value\n",
    "      # print(f\"C = {C}: Number of support vectors = {sum(n_support_vectors)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145, 145, 30)\n",
      "(145, 145)\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16] [10776    46  1428   830   237   483   730    28   478    20   972  2455\n",
      "   593   205  1265   386    93]\n",
      "[ 0 11  2 14 10  3  6 12  5  8 15  4 13 16  1  7  9]\n",
      "(3797, 30)\n",
      "(3797,)\n",
      "[0.9317882538846458, 0.9399525941532789, 0.9436397155649197, 0.9446931788253885, 0.9017645509612853, 0.9483803002370292, 0.9841980510929681, 0.9902554648406637, 0.9020279167764024, 0.9678693705557019, 0.9894653673953121, 0.9928891229918356]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"ML_SVM.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1Xa88GcUIDKDUFGXIkLbVu6ynsc8qj0nT\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "import os,time\n",
    "from sklearn.multiclass import  OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "hyp_data = sio.loadmat(\"D:\\Masters\\sem2\\gnr602/nn_bagging\\Indian_pines_corrected.mat\")\n",
    "gt_data = sio.loadmat(\"D:\\Masters\\sem2\\gnr602/nn_bagging\\Indian_pines_gt.mat\")\n",
    "\n",
    "data = hyp_data[sorted(hyp_data.keys())[-1]]\n",
    "\n",
    "def applyPCA(X, n_components=30, seed=1):\n",
    "    newX = np.reshape(X, (-1, X.shape[2]))\n",
    "    pca = PCA(n_components=n_components, whiten=True, random_state=seed)\n",
    "    newX = pca.fit_transform(newX)\n",
    "    newX = np.reshape(newX, (X.shape[0], X.shape[1], n_components))\n",
    "    return newX\n",
    "\n",
    "data.shape\n",
    "\n",
    "data = applyPCA(data)\n",
    "data.shape\n",
    "\n",
    "labels = gt_data[sorted(gt_data.keys())[-1]]\n",
    "\n",
    "print(data.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "data = data.reshape(data.shape[0]*data.shape[1],data.shape[2])\n",
    "data.shape\n",
    "\n",
    "labels = labels.reshape(-1,1)\n",
    "labels.shape\n",
    "\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "print(unique,counts)\n",
    "\n",
    "count_sort_ind = np.argsort(-counts)\n",
    "print(unique[count_sort_ind])\n",
    "counts[count_sort_ind]\n",
    "\n",
    "data.shape\n",
    "\n",
    "combine = np.concatenate((data,labels),axis=1)\n",
    "combine\n",
    "\n",
    "combine = np.delete(combine,np.where(combine[:,-1]==0),axis=0)\n",
    "combine = np.delete(combine,np.where(combine[:,-1]==1),axis=0)\n",
    "combine = np.delete(combine,np.where(combine[:,-1]==2),axis=0)\n",
    "combine = np.delete(combine,np.where(combine[:,-1]==4),axis=0)\n",
    "combine = np.delete(combine,np.where(combine[:,-1]==5),axis=0)\n",
    "combine = np.delete(combine,np.where(combine[:,-1]==7),axis=0)\n",
    "combine = np.delete(combine,np.where(combine[:,-1]==8),axis=0)\n",
    "combine = np.delete(combine,np.where(combine[:,-1]==9),axis=0)\n",
    "combine = np.delete(combine,np.where(combine[:,-1]==11),axis=0)\n",
    "combine = np.delete(combine,np.where(combine[:,-1]==12),axis=0)\n",
    "combine = np.delete(combine,np.where(combine[:,-1]==13),axis=0)\n",
    "combine = np.delete(combine,np.where(combine[:,-1]==15),axis=0)\n",
    "combine = np.delete(combine,np.where(combine[:,-1]==16),axis=0)\n",
    "\n",
    "combine.shape\n",
    "\n",
    "df = pd.DataFrame(combine)\n",
    "\n",
    "df\n",
    "\n",
    "data = np.array(combine)[:,:-1]\n",
    "labels = np.array(combine)[:,-1]\n",
    "\n",
    "print(data.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "C_values = [0.1, 1, 10, 100]\n",
    "kernel_type = ['linear','poly','rbf']\n",
    "accuracy = []\n",
    "\n",
    "for kernel in kernel_type:\n",
    "  for C in C_values:\n",
    "      # Initialize SVM classifier with current C value\n",
    "      svm = SVC(kernel=kernel, C=C)\n",
    "\n",
    "      start_time1 = time.time()\n",
    "      svm_ovr = OneVsRestClassifier(svm).fit(X_train, y_train)\n",
    "      Time_taken_ovr = time.time() - start_time1\n",
    "      y_test_ovr = svm_ovr.predict(data)\n",
    "\n",
    "      acc_ovr = accuracy_score(labels, y_test_ovr)\n",
    "      accuracy.append(acc_ovr)\n",
    "\n",
    "      \n",
    "      # # Train SVM classifier\n",
    "      # svm.fit(X_train, y_train)\n",
    "      \n",
    "      # # Get number of support vectors\n",
    "      # n_support_vectors = svm.n_support_\n",
    "      \n",
    "      # # Print number of support vectors for current C value\n",
    "      # print(f\"C = {C}: Number of support vectors = {sum(n_support_vectors)}\")\n",
    "\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
